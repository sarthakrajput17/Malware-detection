import numpy as np
import pandas as pd
import nltk
from nltk.corpus import stopwords
import string


df = pd.read_csv("emails.csv")
df.head()

  
  df.shape
  
  df.columns
  
  df.drop_duplicates(inplace=True)
print(df.shape)

  
  print(df.isnull().sum())

  
  nltk.download("stopwords")

  
  def process(text):
    nopunc = [char for char in text if char not in string.punctuation]
    nopunc = ''.join(nopunc)
    clean = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]
    return clean
# to show the tokenization
df['text'].head().apply(process)

  
  from sklearn.feature_extraction.text import CountVectorizer
message = CountVectorizer(analyzer=process).fit_transform(df['text'])

  
  from sklearn.model_selection import train_test_split
xtrain, xtest, ytrain, ytest = train_test_split(message, df['spam'], test_size=0.20, random_state=0)
print(message.shape)

  
  from sklearn.naive_bayes import MultinomialNB
classifier = MultinomialNB().fit(xtrain, ytrain)
print(ytrain)


print(classifier.predict(xtrain))
print(ytrain.values)


from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
pred = classifier.predict(xtrain)
print("Classification_Table: \n")
print(classification_report(ytrain, pred))
print()
print("Confusion Matrix: \n", confusion_matrix(ytrain, pred))
print("\n")
print("Accuracy: \n", accuracy_score(ytrain, pred))


print(classifier.predict(xtest))
print(ytest.values)


from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
pred = classifier.predict(xtest)
print("Classification_Table: \n")
print(classification_report(ytest, pred))
print()
print("Confusion Matrix: \n", confusion_matrix(ytest, pred))
print("\n")
print("Accuracy: \n", accuracy_score(ytest, pred))
